version: '2'

services:

  elasticsearch:
    build:
      context: elasticsearch/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"
      ELASTIC_PASSWORD: changeme
    networks:
      - elk

  logstash:
    build:
      context: logstash/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
    ports:
      - "5000:5000"
      - "9600:9600"
      - "5044:5044"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    networks:
      - elk
    depends_on:
      - elasticsearch

  kibana:
    build:
      context: kibana/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - ./kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
    ports:
      - "5601:5601"
    networks:
      - elk
    depends_on:
      - elasticsearch

  filebeat:
    build:
      context: filebeat/
    volumes:
      - ./filebeat/logs_kannel/:/usr/share/filebeat/kannel_logs:ro
      - /var/run/docker.sock:/var/run/docker.sock
#    ports:
#      - "5601:5601"
    networks:
      - elk
    depends_on:
      - logstash
  
#  elastalert:
#    build:
#      context: elastalert-docker/
#    volumes:
##      - ./elastalert-docker/config/:/opt/config
#      - ./elastalert-docker/logs/:/opt/logs
#      - ./elastalert-docker/rules/:/opt/rules
#      - ./elastalert-docker/smtp-auth.yml:/opt/smtp-auth.yml
#    networks:
#      - elk
#    depends_on:
#      - logstash
#
#  zoo1:
#    image: zookeeper:3.4.9
#    hostname: zoo1
#    ports:
#      - "2181:2181"
#    environment:
#        ZOO_MY_ID: 1
#        ZOO_PORT: 2181
#        ZOO_SERVERS: server.1=zoo1:2888:3888
#    volumes:
#      - ./zk-single-kafka-single/zoo1/data:/data
#      - ./zk-single-kafka-single/zoo1/datalog:/datalog
#    networks:
#      - elk
#
#  kafka1:
#    image: confluentinc/cp-kafka:5.3.0
#    hostname: kafka1
#    ports:
#      - "9092:9092"
#    environment:
#      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://localhost:9092
#      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
#      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
#      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
#      KAFKA_BROKER_ID: 1
#      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
#      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#    volumes:
#      - ./zk-single-kafka-single/kafka1/data:/var/lib/kafka/data
#    networks:
#      - elk
#    depends_on:
#      - zoo1

networks:
  elk:
    driver: bridge
